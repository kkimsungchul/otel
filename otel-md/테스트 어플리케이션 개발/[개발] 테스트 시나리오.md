# 테스트 설명

## 개발 언어
- Java (SpringBoot)
- Python (Django, Flask)

## 애플리케이션 유형(8가지)
- SDK (SpringBoot)
- SDK (Django)
- SDK (Flask) - New ==> 부하테스트
- Agent (SpringBoot)
- Auto (SpringBoot)
- Auto (Django)
- Auto (Flask) - New ==> 부하테스트
- MSA (SpringBoot) - New ==> 응답속도 지연테스트

## 테스트 개요
| 유형 | 발생 원인 | 결과 | 예시 |
| :--- | :---: | :---: | :---: |
| A. 응답속도 지연 테스트 | 슬로우 쿼리, 잘못 만들어진 비즈니스 로직 | 응답속도 지연 | 웹페이지 접속 시 속도 지연 |
| B. 트래픽 부하 테스트 | 과도한 트래픽 | CPU 사용량 증가 | 티켓팅 시 과도한 트래픽 발생으로 인한 대기인원 증가 |

---

# 테스트 시나리오
## A. 응답속도 지연 테스트
- Step1. 배치 파일 실행
    * 1.1. dashboard_run.bat, start_distributed-system.bat 실행
    * **[비고]** 실행파일 경로
	C:\otel\application
	C:\otel\application\distributed-system
- Step2. URL 호출
    * 2.1. URL 호출 및 랜덤하게 발생하는 오류 탐지
    * **[예상결과]** True or SERVER ERROR, status=500
    * **[비고]** URL(http://localhost:10010/board)
- Step3. 모니터링 툴 접속(Jaeger)
    * 3.1. Service에서 board-system 선택 후 find trace 클릭
    * 3.2. 검색된 trace에서 오류 발생/미발생 트레이스 선택
    * 3.3. 서비스 지연 시간 확인 및 원인 파악
    * **[예상결과]**
	HTTP Statistics > Request Count 대시보드의 GET [500] - /user
	Span Attributes error.type=500 / Events: event=exception
    * **[비고]**
	예거 웹 주소(http://localhost:16686)
- Step4. 모니터링 툴 접속(Grafana)
    * 4.1. Dashboards > SpringBoot MSA Monitoring 혹은 비고란의 URL 접속
    * 4.2. Duration time 대시보드에서 서비스 지연 시간 확인 및 traceid 확인
    * 4.3. Explore에서 Outline jaeger 선택, traceid 입력 후 Run query 클릭
    * 4.4. span attributes에서 otel.status_code=“ERROR”, event에서 exception.message=“Read timed out” 확인
    * **[예상결과]**
	Span Attributes otel.status_code=“ERROR”Events
	exception.message=“Read timed out”

    * **[비고]**
	그라파나 웹 주소(http://localhost:3000)
	        
	 그라파나 계정
		Id: admin
		Pw: admin
	        
		 SpringBoot Dashboard URL 주소(http://localhost:3000/d/springboot_msa_monitoring/springboot-msa-monitoring?orgId=1&refresh=5s)


## B. 트래픽 부하 테스트
- Step1. 배치 파일 실행
    * 1.1. dashboard_run.bat, flask_run_server.bat 실행
    * **[비고]** 배치파일 경로(C:\otel\application)
- Step2. 수신자 이메일 추가
    * 2.1 Alerting > Contact points 혹은 아래의 URL 접속(http://localhost:3000/alerting/notifications?search=)
    * 2.2 Grafana-default-email Edit 클릭
    * 2.3 Addresses에 메일 수신자 이메일 주소 기입(사내메일 가능)
    * 2.4 Test 버튼 클릭해서 알람 정상 수신 확인
    * 2.5 알람이 정상적으로 수신되면 Save contact point 클릭
    * **[예상결과]**
      	알람 제목(메일):[FIRING:1] TestAlert Grafana
    * **[비고]** 그라파나 웹 주소(http://localhost:3000)
	     그라파나 계정(Id: admin / Pw: admin)
- Step3. 수신자 슬랙 채널 추가
    * 3.1 Alerting > Contact points 혹은 아래의 URL 접속(http://localhost:3000/alerting/notifications?search=)
    * 3.2 Grafana-default-slack Edit 클릭
    * 3.3 Addresses에 슬랙 채널의 webhook url 기입
    * 3.4 Test 버튼 클릭해서 알람 정상 수신 확인
    * 3.5 알람이 정상적으로 수신되면 Save contact point 클릭
    * **[예상결과]** 알람 제목(슬랙):[FIRING:1] TestAlert Grafana
    * **[비고]** 그라파나 웹 주소(http://localhost:3000)
	     그라파나 계정(Id: admin / Pw: admin)
- Step4. 대시보드 확인
    * 4.1 Prometheus 기존 data 삭제
    * 4.2 Grafana Dashboards > Flask Monitoring 혹은 URL 접속(http://localhost:3000/d/flask-monitoring/flask-monitoring?orgId=1&refresh=5s)
    * 4.3 대시보드에 데이터 없는 것 확인
    * **[예상결과]** No data
    * **[비고]** 프로메테우스 데이터 경로(C:\prometheus-2.52.0.windows-amd64\data)
- Step5. Apache Jmeter 실행
    * 5.1 jmeter_run.bat 실행
    * 5.2 HTTP Request.jmx 파일 import 후 run
    * **[비고]** 배치파일 경로(C:\otel\application)
- Step6. 정상 테스트 진행
    * 6.1 정상 테스트 우클릭 후 Start 클릭
    * 6.2 Dashboards > Flask Monitoring 혹은 비고의 URL 접속
    * **[예상결과]** 모든 응답 정상
    * **[비고]** Flask Dashboard URL 주소(http://localhost:3000/d/flask-monitoring/flask-monitoring?orgId=1&refresh=5s)
          	각각의 작업 완료 후 다음 테스트 진행

- Step7. 포화 테스트 진행
    * 7.1 포화 테스트 우클릭 후 Start 클릭
    * 7.2 Dashboards > Flask Monitoring 혹은 비고의 URL 접속
    * **[예상결과]** 간헐적으로 500 에러 발생
    * **[비고]** Flask Dashboard URL 주소(http://localhost:3000/d/flask-monitoring/flask-monitoring?orgId=1&refresh=5s)
          	각각의 작업 완료 후 다음 테스트 진행

- Step8. 비정상 테스트 진행
    * 8.1 비정상 테스트 우클릭 후 Start 클릭
    * 8.2 Dashboards > Flask Monitoring 혹은 비고의 URL 접속
    * **[예상결과]** 대부분의 응답 500에러
		CPU 사용률 > 70%
		알람 수신
    * **[비고]** Flask Dashboard URL 주소(http://localhost:3000/d/flask-monitoring/flask-monitoring?orgId=1&refresh=5s)
          	각각의 작업 완료 후 다음 테스트 진행

- Step9. 메일 알람 확인
    * 9.1 사전작업1에서 기재한 메일함 확인
    * 9.2. [FIRING]으로 수신된 메일 확인
    * 9.3. [Resorved]으로 수신된 메일 확인
    * **[예상결과]** 메일 정상 수신

- Step10. 슬랙 알람 확인
    * 10.1 사전작업1에서 기재한 슬랙 채널 확인
    * 10.2 [FIRING]으로 수신된 알람 확인
    * 10.3. [Resorved]으로 수신된 알람 확인
    * **[예상결과]** 알람 정상 수신


---
## 전체 개발 내용 시연 (SpringBoot)
- 로직 설명
- http://localhost/sdk-java/board/10/
- http://localhost/auto-java/log/
- prometheus: http://localhost:9090/
    - jvm_memory_usedMemory
    - jvm_memory_heapUsage
- jaeger: http://localhost:16686/search
    - auto 방식과 sdk 방식의 span 쌓이는 차이
- grafana: http://localhost:3000
    - prometheus, jaeger 통합 모니터링

## 예외 테스트 (SpringBoot)
### Internal sever Exception
- URL 호출 (http://localhost/auto-java/user/)
- grafana: http://localhost:3000
- SpringBoot dashboard에서 http response 확인
- Tags에서 500 error, logs에서 error log 확인 가능

## 부하 테스트 (Flask)
- Apache jmeter 사용
- 실행 경로: apache-jmeter-5.6.3/bin/jmeter.bat
- 테스트 파일 경로: otel\application\apache-jmeter-test\HTTP Request.jmx
- Grafana로 Flask Application의 CPU, Memory 증가량 확인
- 일정 수준 이상(CPU 70% 이상) 증가 시 이메일 발송
